{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import evaluation\n",
    "import make_prediction as mp\n",
    "\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('../data/training.csv', parse_dates= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=df.sample(frac=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv('../data/testing.csv', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id\n",
       "s50045366     448\n",
       "s50096611     628\n",
       "s50131077     438\n",
       "s50262812     975\n",
       "s50324991     761\n",
       "             ... \n",
       "x8385515     2876\n",
       "x8396038      638\n",
       "x8402864      486\n",
       "x899896       896\n",
       "x9683723     1664\n",
       "Length: 600, dtype: int64"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby('product_id').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating difference features \n",
    "\n",
    "#sample['pct_change']=sample['sensor_t4'].diff()\n",
    "\n",
    "def pct_change(variable,df):\n",
    "    for var in variable:\n",
    "        if var in df.columns:\n",
    "            df[var+'_pct_change']=df[var].pct_change()\n",
    "        else:\n",
    "            print('Column does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "slist =['sensor_t4','sensor_t1','sensor_t5','sensor_q1','sensor_s4','sensor_t6','sensor_q2',\n",
    "       'sensor_t9','sensor_s3','sensor_t2','sensor_t7','sensor_s1','sensor_t3','sensor_s2','sensor_t8']\n",
    "\n",
    "s=pct_change(slist,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=pct_change(slist,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some products are missing process \n",
    "#### Like s50016128 , this product has only gone throught process B and C "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(x):\n",
    "    f=np.std(x)\n",
    "    return f\n",
    "\n",
    "def mean(x):\n",
    "    f=np.mean(x)\n",
    "    return f\n",
    "\n",
    "def entropy(s):\n",
    "    px = s.value_counts() / s.shape[0]\n",
    "    lpx = np.log2(px)\n",
    "    ent = -1.0*(px*lpx).sum()\n",
    "    return ent \n",
    "\n",
    "def var(x):\n",
    "    return np.var(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numerical data from sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregrations ={\n",
    "                'sensor_t4':[min,max,mean,var,entropy],\n",
    "                'sensor_t1':[min,max,mean,var,entropy],\n",
    "                'sensor_t5':[min,max,mean,var,entropy],\n",
    "                'sensor_q1':[min,max,mean,var,entropy],\n",
    "                'sensor_s4':[min,max,mean,var,entropy],\n",
    "                'sensor_t6':[min,max,mean,var,entropy],\n",
    "                'sensor_s3':[min,max,mean,var,entropy],\n",
    "                'sensor_q2':[min,max,mean,var,entropy],\n",
    "                'sensor_t9':[min,max,mean,var,entropy],\n",
    "                'sensor_t2':[min,max,mean,var,entropy],\n",
    "                'sensor_s3':[min,max,mean,var,entropy],\n",
    "                'sensor_t7':[min,max,mean,var,entropy],\n",
    "                'sensor_s2':[min,max,mean,var,entropy],\n",
    "                'sensor_t1':[min,max,mean,var,entropy],\n",
    "                'sensor_t3':[min,max,mean,var,entropy],\n",
    "                'sensor_s2':[min,max,mean,var,entropy],\n",
    "                'sensor_t8':[min,max,mean,var,entropy],\n",
    "                'timestamp':[min,max],\n",
    "                'flow_id':['last'],\n",
    "                'lot_id':['last'],\n",
    "                'flag_b2':[entropy],\n",
    "                'flag_c2':[entropy],\n",
    "                'flag_e': [entropy],\n",
    "                'flag_a2':[entropy],\n",
    "                'flag_a4':[entropy],\n",
    "                'flag_b1':[entropy],\n",
    "                'flag_d': [entropy],\n",
    "                'flag_a1':[entropy],\n",
    "                'flag_b3':[entropy],\n",
    "                'flag_b4':[entropy],\n",
    "                'flag_c1':[entropy],\n",
    "                'flag_a3':[entropy],\n",
    "                'flag_a5':[entropy],\n",
    "                'flag_b2':['last','first',mean],\n",
    "                'flag_c2':['last','first',mean],\n",
    "                'flag_e':['last','first',mean],\n",
    "                'flag_a2':['last','first',mean],\n",
    "                'flag_a4':['last','first',mean],\n",
    "                'flag_b1':['last','first',mean],\n",
    "                'flag_d':['last','first',mean],\n",
    "                'flag_a1':['last','first',mean],\n",
    "                'flag_b3':['last','first',mean],\n",
    "                'flag_b4':['last','first',mean],\n",
    "                'flag_c1':['last','first',mean],\n",
    "                'flag_a3':['last','first',mean],\n",
    "                'flag_a5':['last','first',mean],\n",
    "                'sensor_t4_pct_change':[min,max],\n",
    "                'sensor_t1_pct_change':[min,max],\n",
    "                'sensor_t5_pct_change':[min,max],\n",
    "                'sensor_q1_pct_change':[min,max],\n",
    "                'sensor_s4_pct_change':[min,max],\n",
    "                'sensor_t6_pct_change':[min,max],\n",
    "                'sensor_s3_pct_change':[min,max],\n",
    "                'sensor_q2_pct_change':[min,max],\n",
    "                'sensor_t9_pct_change':[min,max],\n",
    "                'sensor_t2_pct_change':[min,max],\n",
    "                'sensor_s3_pct_change':[min,max],\n",
    "                'sensor_t7_pct_change':[min,max],\n",
    "                'sensor_s2_pct_change':[min,max],\n",
    "                'sensor_t1_pct_change':[min,max],\n",
    "                'sensor_t3_pct_change':[min,max],\n",
    "                'sensor_s2_pct_change':[min,max],\n",
    "                'sensor_t8_pct_change':[min,max]\n",
    "                \n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply aggregation functions\n",
    "def aggregation(df):\n",
    "    group_obj=df.groupby(['product_id','process'])\n",
    "    '''change the groupby object to full df'''\n",
    "    f=group_obj.agg(aggregrations)\n",
    "\n",
    "# renaming columns with multiIndex levels \n",
    "    f.columns = [\"_\".join(x) for x in f.columns.ravel()]\n",
    "#unstacking the agg features to create separate feature for each process\n",
    "    funstack=f.unstack(level=1)\n",
    "# Renaming these features \n",
    "    funstack.columns = [\"_\".join(x) for x in funstack.columns.ravel()]\n",
    "#flattening the index \n",
    "    funstack.reset_index(inplace=True)\n",
    "    return funstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat=aggregation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_test=aggregation(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 565)"
      ]
     },
     "execution_count": 978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adding time duration \n",
    "##### count total seconds spent on each process \n",
    "######tot_seconds_proccessA = 290\n",
    "######tot_seconds_proccessB = 456\n",
    "sample['timestamp_seconds']=sample.loc['timestamp'].dt.second.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting string to datetime to calculate time spent\n",
    "timestamplist =['timestamp_max_A','timestamp_min_A','timestamp_max_B','timestamp_min_B','timestamp_max_C',\n",
    "                 'timestamp_min_C','timestamp_max_D','timestamp_min_D']\n",
    "\n",
    "# Fill the Missing timestamps as 0 \n",
    "## Assumption: If no time was spent on the stage then it is meaningful 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funstack.loc[:,timestamplist].apply(pd.to_datetime)\n",
    "for timecolumn in timestamplist:\n",
    "    flat_test[timecolumn]= flat_test[timecolumn].apply(lambda x : pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the Missing timestamps as 0 \n",
    "## Assumption: If no time was spent on the stage then it is meaningful 0\n",
    "flat['timeSpent_A'] = (flat['timestamp_max_A'] - flat['timestamp_min_A']).fillna(pd.Timedelta(seconds=0))/np.timedelta64(1, 's')\n",
    "flat['timeSpent_B'] = (flat['timestamp_max_B'] - flat['timestamp_min_B']).fillna(pd.Timedelta(seconds=0))/np.timedelta64(1, 's')\n",
    "flat['timeSpent_C'] = (flat['timestamp_max_C'] - flat['timestamp_min_C']).fillna(pd.Timedelta(seconds=0))/np.timedelta64(1, 's')\n",
    "flat['timeSpent_D'] = (flat['timestamp_max_D'] - flat['timestamp_min_D']).fillna(pd.Timedelta(seconds=0))/np.timedelta64(1, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the Missing timestamps as 0 \n",
    "## Assumption: If no time was spent on the stage then it is meaningful 0\n",
    "flat_test['timeSpent_A'] = (flat_test['timestamp_max_A'] - flat_test['timestamp_min_A']).fillna(pd.Timedelta(seconds=0))/np.timedelta64(1, 's')\n",
    "flat_test['timeSpent_B'] = (flat_test['timestamp_max_B'] - flat_test['timestamp_min_B']).fillna(pd.Timedelta(seconds=0))/np.timedelta64(1, 's')\n",
    "flat_test['timeSpent_C'] = (flat_test['timestamp_max_C'] - flat_test['timestamp_min_C']).fillna(pd.Timedelta(seconds=0))/np.timedelta64(1, 's')\n",
    "flat_test['timeSpent_D'] = (flat_test['timestamp_max_D'] - flat_test['timestamp_min_D']).fillna(pd.Timedelta(seconds=0))/np.timedelta64(1, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_test.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 569)"
      ]
     },
     "execution_count": 982,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_test['Total_time_spent'] = flat_test.loc[:,\n",
    "                                    ['timeSpent_A','timeSpent_B','timeSpent_C','timeSpent_D']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nflat['max_timespent_A']= np.max(flat['timeSpent_A'])\\nflat['max_timespent_B']= np.max(flat['timeSpent_B'])\\nflat['max_timespent_C']= np.max(flat['timeSpent_C'])\\nflat['max_timespent_D']= np.max(flat['timeSpent_D'])\\n\\nflat\""
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Extract time of the process \n",
    "### Hpothesis : may be parts going through production during day have high loq qc score due to heat generated by friction\n",
    "\n",
    "### Hypothesis 2: total time spend by a product on a particular process will tell us how much deviation is there in the current product \n",
    "'''\n",
    "flat['max_timespent_A']= np.max(flat['timeSpent_A'])\n",
    "flat['max_timespent_B']= np.max(flat['timeSpent_B'])\n",
    "flat['max_timespent_C']= np.max(flat['timeSpent_C'])\n",
    "flat['max_timespent_D']= np.max(flat['timeSpent_D'])\n",
    "\n",
    "flat'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining the Target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../data/training_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged= flat.merge(labels, left_on='product_id', right_on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('../data/trainig_dataV11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout= flat.merge(labels, left_on='product_id', right_on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4405, 571)"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = merged.sample(frac=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=merged.drop(holdout.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape (3524, 523)\n",
      "external set shape (881, 572)\n"
     ]
    }
   ],
   "source": [
    "print(\"training shape\",train.shape)\n",
    "print(\"external set shape\",holdout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['row_id']= holdout.reset_index().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_products = holdout['product_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2638    x18338263\n",
       "668     s64647679\n",
       "1213    s76786960\n",
       "478     s59877646\n",
       "530     s61083173\n",
       "          ...    \n",
       "4386     x9631590\n",
       "321     s56897875\n",
       "2309    x11390046\n",
       "888     s69676814\n",
       "655     s64322497\n",
       "Name: product_id, Length: 881, dtype: object"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout['product_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2638    x18338263\n",
       "668     s64647679\n",
       "1213    s76786960\n",
       "478     s59877646\n",
       "530     s61083173\n",
       "          ...    \n",
       "4386     x9631590\n",
       "321     s56897875\n",
       "2309    x11390046\n",
       "888     s69676814\n",
       "655     s64322497\n",
       "Name: product_id, Length: 881, dtype: object"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= flat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_id', 'sensor_t4_min_A', 'sensor_t4_min_B', 'sensor_t4_min_C',\n",
       "       'sensor_t4_min_D', 'sensor_t4_max_A', 'sensor_t4_max_B',\n",
       "       'sensor_t4_max_C', 'sensor_t4_max_D', 'sensor_t4_mean_A',\n",
       "       ...\n",
       "       'sensor_t8_pct_change_min_D', 'sensor_t8_pct_change_max_A',\n",
       "       'sensor_t8_pct_change_max_B', 'sensor_t8_pct_change_max_C',\n",
       "       'sensor_t8_pct_change_max_D', 'timeSpent_A', 'timeSpent_B',\n",
       "       'timeSpent_C', 'timeSpent_D', 'Total_time_spent'],\n",
       "      dtype='object', length=570)"
      ]
     },
     "execution_count": 985,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataRobot - Project building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datarobot as dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datarobot.rest.RESTClientObject at 0x18cbcc700>"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.Client(token='NWVlYWVmNzI4YjcxY2IyODE2ZTJhOTg5OnhSdjlqSEZ2NlU5cHc4WWQwZlh1RHNkbGZGREE0dlQzQnB5L3k2V2d3a2c9', endpoint='https://app.datarobot.com/api/v2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition=dr.RandomCV(reps=4, holdout_pct=0, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: 5f2b9c98ce243f0a4ec5db90\n"
     ]
    }
   ],
   "source": [
    "project = dr.Project.create(sourcedata=merged,\n",
    "                           project_name='LUSY_Training_only_V5_FULL')\n",
    "print('Project ID: {}'.format(project.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare the external holdout set \n",
    "\n",
    "run the preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the project\n",
    "proj=dr.Project.get('5f29d92cd6e13f37136dcc0a')\n",
    "# chose the model \n",
    "model = dr.Model.get(project=proj.id,\n",
    "                     model_id='5f2cb885735d1f06c8953475')\n",
    "#upload the external dataset \n",
    "external= proj.upload_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PredictionDataset('predict.csv'), PredictionDataset('predict.csv')]"
      ]
     },
     "execution_count": 987,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.get_datasets()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_id=proj.id\n",
    "model_id=model.id\n",
    "ext_id= external.id\n",
    "#ext_id= proj.get_datasets()[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_(project_id,model_id,ext_id):\n",
    "    #upload external set\n",
    "    ## Check if there is an external set already. If yes, then get the dataset.id instead of uploading a new one \n",
    "    model = dr.Model.get(project=proj_id,\n",
    "                     model_id=model_id)\n",
    "    predict_job=model.request_predictions(ext_id)\n",
    "    predict_job.wait_for_completion()\n",
    "    #get predictions\n",
    "    predictions = predict_job.get_result_when_complete()\n",
    "    #predictions['exp_predictions'] = np.exp(predictions['prediction'])\n",
    "    #predictions['row_id']= predictions.reset_index().index\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_results(predictions,actual_df):\n",
    "    result=actual_df.merge(predictions,left_on='row_id',right_on='row_id', how='left')\n",
    "    #holdout_with_target= result.merge(labels, left_on='product_id', right_on='product_id', how='left')\n",
    "    return amape(result['qc_reading'],result['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "r =get_predictions_(proj_id,model_id,ext_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 2)"
      ]
     },
     "execution_count": 991,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-92-8330c5c7e946>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  actual[a] = 2000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4729"
      ]
     },
     "execution_count": 992,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = join_results(r,holdout)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## current best scor e\n",
    "0.1287\n",
    "bestmodelid='5f28d4b2ce243f3780c8546c'\n",
    "bestprojID='5f28a52d6c6a7a330eaff775'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models ={'projid':'5f29d92cd6e13f37136dcc0a','model_id':'5f2b898fce243f09f3c5dadf','score':0.0825}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'projid': '5f29d92cd6e13f37136dcc0a',\n",
       " 'model_id': '5f2b898fce243f09f3c5dadf',\n",
       " 'score': 0.0825}"
      ]
     },
     "execution_count": 902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models.update('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "\n",
    "\n",
    "#### Beat 0.121 score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amape(actual,pred):\n",
    "    #actual, pred = np.array(actual), np.array(pred)\n",
    "    for a in actual:\n",
    "        if a < 2000000:\n",
    "            actual[a] = 2000000\n",
    "            #mape =np.round(np.mean(np.abs((actual - pred) / actual)),4)\n",
    "        else:\n",
    "            None\n",
    "            mape =np.round(np.mean(np.abs((actual - pred) / actual)),4)\n",
    "            return mape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ProjectID                  model_id  score insample\n",
      "0  5f281d9bce243f25ac54c7a9  5f281f78984a434cced832fa  0.181      yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scorecard = {'ProjectID': ['5f281d9bce243f25ac54c7a9'],\n",
    "        'model_id': ['5f281f78984a434cced832fa'],\n",
    "             'score':[0.181],\n",
    "     'insample':['yes']\n",
    "        }\n",
    "\n",
    "scores = pd.DataFrame(scorecard, columns = ['ProjectID', 'model_id','score','insample'])\n",
    "\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can only append a dict if ignore_index=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-970-b457ae7f961a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'ProjectID'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'model_id'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'insample'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'no'\u001b[0m \u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/python3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   7698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7700\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only append a dict if ignore_index=True\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7701\u001b[0m                 \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7702\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can only append a dict if ignore_index=True"
     ]
    }
   ],
   "source": [
    "#scores.append({'ProjectID' : proj.id , 'model_id' : model.id,'score':score,'insample':'no' } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submitted models \n",
    "\n",
    "V4 FULL projec - https://app.datarobot.com/projects/5f29d92cd6e13f37136dcc0a/models/5f2a2104ce243f4ab7c854a6/blueprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectID</th>\n",
       "      <th>model_id</th>\n",
       "      <th>score</th>\n",
       "      <th>insample</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5f2902676c6a7a2df18d88c3</td>\n",
       "      <td>5f2caee19071ae0609b632cc</td>\n",
       "      <td>0.181</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ProjectID                  model_id  score insample  2\n",
       "0  5f2902676c6a7a2df18d88c3  5f2caee19071ae0609b632cc  0.181      yes  0"
      ]
     },
     "execution_count": 958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
